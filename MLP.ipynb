{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8dcf2c68-b2fb-4ae0-9bd8-584476a6977c",
   "metadata": {},
   "source": [
    "# Multi-Layer-Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1cac9e9-d7ff-4731-a4ed-38ce01a6e8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a724ea-012b-487e-b29c-3cef4b15b62f",
   "metadata": {},
   "source": [
    "### 1. 논리 게이트"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0477a339-3fdf-4a9d-b4d0-4a902a6dc6e3",
   "metadata": {},
   "source": [
    "#### 1-1. 논리 게이트 예측 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4ea6b88-c589-4546-98cb-40f5faa85351",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def numerical_derivative(f, x):\n",
    "    delta_x = 1e-4 # 0.0001\n",
    "    grad = np.zeros_like(x)\n",
    "    \n",
    "    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
    "    \n",
    "    while not it.finished:\n",
    "        idx = it.multi_index\n",
    "        tmp_val = x[idx]\n",
    "        x[idx] = float(tmp_val) + delta_x\n",
    "        fx1 = f(x)\n",
    "        \n",
    "        x[idx] = tmp_val - delta_x\n",
    "        fx2 = f(x)\n",
    "        grad[idx] = (fx1 - fx2) / (2  * delta_x)\n",
    "        \n",
    "        x[idx] = tmp_val\n",
    "        it.iternext()\n",
    "        \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e6fe3d7-c184-4a99-b5dc-c254d7f5b743",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogicGate:\n",
    "    \n",
    "    def __init__(self, gate_name, xdata, tdata):\n",
    "        \n",
    "        self.name = gate_name\n",
    "        \n",
    "        self.__xdata = xdata.reshape(4,2)\n",
    "        self.__tdata = tdata.reshape(4,1)\n",
    "        \n",
    "        self.__W = np.random.rand(2, 1)\n",
    "        self.__b = np.random.rand(1)\n",
    "        \n",
    "        self.__learning_rate = 1e-2\n",
    "        \n",
    "    def __loss_func(self):\n",
    "        \n",
    "        delta = 1e-7\n",
    "        \n",
    "        z = np.dot(self.__xdata, self.__W) + self.__b\n",
    "        y = sigmoid(z)\n",
    "        \n",
    "        return -np.sum( self.__tdata * np.log(y + delta) + (1-self.__tdata) * np.log((1-y) + delta))\n",
    "    \n",
    "    def error_val(self):\n",
    "        \n",
    "        delta = 1e-7\n",
    "        \n",
    "        z = np.dot(self.__xdata, self.__W) + self.__b\n",
    "        y = sigmoid(z)\n",
    "        \n",
    "        return - np.sum( self.__tdata * np.log(y + delta) + (1 - self.__tdata) * np.log((1-y) + delta))\n",
    "    \n",
    "    def train(self):\n",
    "        \n",
    "        f = lambda x : self.__loss_func()\n",
    "        \n",
    "        print(\"Initial error value = \", self.error_val())\n",
    "        \n",
    "        for step in range(8001):\n",
    "            \n",
    "            self.__W -= self.__learning_rate * numerical_derivative(f, self.__W)\n",
    "            \n",
    "            self.__b -= self.__learning_rate * numerical_derivative(f, self.__b)\n",
    "            \n",
    "            if (step % 400 == 0):\n",
    "                print(\"step = \", step, \"error value = \", self.error_val())\n",
    "                \n",
    "    def predict(self, input_data):\n",
    "        \n",
    "        z = np.dot(input_data, self.__W) + self.__b\n",
    "        y = sigmoid(z)\n",
    "        \n",
    "        if y > 0.5:\n",
    "            result = 1 #True\n",
    "        else:\n",
    "            result = 0 #False\n",
    "            \n",
    "        return y, result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df81a138-50f6-4601-9814-3eb8b2eae835",
   "metadata": {},
   "source": [
    "#### 1-2. AND GATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4893954-50b5-46db-8e11-c2d7e31c1e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial error value =  4.635841303140489\n",
      "step =  0 error value =  4.57896675139003\n",
      "step =  400 error value =  1.5769303987147492\n",
      "step =  800 error value =  1.1623360316089433\n",
      "step =  1200 error value =  0.9308593228660458\n",
      "step =  1600 error value =  0.7793040215253395\n",
      "step =  2000 error value =  0.6708804702350186\n",
      "step =  2400 error value =  0.5889226319877797\n",
      "step =  2800 error value =  0.5245952727131109\n",
      "step =  3200 error value =  0.47269349063641963\n",
      "step =  3600 error value =  0.42991553822166284\n",
      "step =  4000 error value =  0.3940501072606819\n",
      "step =  4400 error value =  0.36355354337548396\n",
      "step =  4800 error value =  0.33731241695478287\n",
      "step =  5200 error value =  0.31450197790425904\n",
      "step =  5600 error value =  0.2944976494574296\n",
      "step =  6000 error value =  0.27681749246952025\n",
      "step =  6400 error value =  0.2610835754619254\n",
      "step =  6800 error value =  0.24699532117515643\n",
      "step =  7200 error value =  0.23431068168302654\n",
      "step =  7600 error value =  0.22283257015187385\n",
      "step =  8000 error value =  0.2123989055917081\n"
     ]
    }
   ],
   "source": [
    "xdata = np.array([ [0, 0], [0, 1], [1, 0], [1, 1] ])\n",
    "tdata = np.array([0, 0, 0, 1])\n",
    "\n",
    "AND_obj = LogicGate(\"AND_GATE\", xdata, tdata)\n",
    "\n",
    "AND_obj.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "564c91d7-c2f7-4adb-ab59-855baa3df165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AND_GATE \n",
      "\n",
      "[0 0]  =  0 \n",
      "\n",
      "[0 1]  =  0 \n",
      "\n",
      "[1 0]  =  0 \n",
      "\n",
      "[1 1]  =  1 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(AND_obj.name, \"\\n\")\n",
    "\n",
    "test_data = np.array([ [0, 0], [0, 1], [1, 0], [1, 1] ])\n",
    "\n",
    "for input_data in test_data:\n",
    "    (sigmoid_val, logical_val) = AND_obj.predict(input_data)\n",
    "    print(input_data, \" = \", logical_val, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ea9cdf-229c-4edc-9e14-53e9594e825a",
   "metadata": {},
   "source": [
    "#### 1-2. OR GATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd87d9b5-ae4b-4370-90c7-fbe0a54b8079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial error value =  1.9106419411012103\n",
      "step =  0 error value =  1.9078257819924649\n",
      "step =  400 error value =  1.194123007831091\n",
      "step =  800 error value =  0.8492565016631924\n",
      "step =  1200 error value =  0.6522627872140118\n",
      "step =  1600 error value =  0.526129458146585\n",
      "step =  2000 error value =  0.43899837288717813\n",
      "step =  2400 error value =  0.37551096611801565\n",
      "step =  2800 error value =  0.3273744623564773\n",
      "step =  3200 error value =  0.28973049130242345\n",
      "step =  3600 error value =  0.2595526308789194\n",
      "step =  4000 error value =  0.23486271760500352\n",
      "step =  4400 error value =  0.2143164026599313\n",
      "step =  4800 error value =  0.19697007608336564\n",
      "step =  5200 error value =  0.18214308450959735\n",
      "step =  5600 error value =  0.1693328317875151\n",
      "step =  6000 error value =  0.15816059266822344\n",
      "step =  6400 error value =  0.14833586573369356\n",
      "step =  6800 error value =  0.13963229553955145\n",
      "step =  7200 error value =  0.13187102698574962\n",
      "step =  7600 error value =  0.12490895798735849\n",
      "step =  8000 error value =  0.1186302947154184\n"
     ]
    }
   ],
   "source": [
    "xdata = np.array([ [0, 0], [0, 1], [1, 0], [1, 1] ])\n",
    "tdata = np.array([0, 1, 1, 1])\n",
    "\n",
    "OR_obj = LogicGate(\"OR_GATE\", xdata, tdata)\n",
    "\n",
    "OR_obj.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e8d305b-63fc-489c-920a-dad3b3b9d280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OR_GATE \n",
      "\n",
      "[0 0]  =  0 \n",
      "\n",
      "[0 1]  =  1 \n",
      "\n",
      "[1 0]  =  1 \n",
      "\n",
      "[1 1]  =  1 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(OR_obj.name, \"\\n\")\n",
    "\n",
    "test_data = np.array([ [0, 0], [0, 1], [1, 0], [1, 1] ])\n",
    "\n",
    "for input_data in test_data:\n",
    "    (sigmoid_val, logical_val) = OR_obj.predict(input_data)\n",
    "    print(input_data, \" = \", logical_val, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587785f6-2bee-42fc-81b6-581680c99f2d",
   "metadata": {},
   "source": [
    "#### 1-3. NAND GATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d60320cd-34af-40e7-b786-7f5479a0c868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial error value =  2.9853883136340755\n",
      "step =  0 error value =  2.9768401004721308\n",
      "step =  400 error value =  1.6535637704887765\n",
      "step =  800 error value =  1.199760085072825\n",
      "step =  1200 error value =  0.9536851743470895\n",
      "step =  1600 error value =  0.794981066812043\n",
      "step =  2000 error value =  0.6824246403631082\n",
      "step =  2400 error value =  0.5978186346952975\n",
      "step =  2800 error value =  0.5316749473169919\n",
      "step =  3200 error value =  0.4784660561847996\n",
      "step =  3600 error value =  0.43471313477599166\n",
      "step =  4000 error value =  0.3980998990816681\n",
      "step =  4400 error value =  0.36701672638633226\n",
      "step =  4800 error value =  0.34030680175164724\n",
      "step =  5200 error value =  0.3171157818773449\n",
      "step =  5600 error value =  0.2967982909573309\n",
      "step =  6000 error value =  0.2788574004752524\n",
      "step =  6400 error value =  0.2629041432389376\n",
      "step =  6800 error value =  0.24862966568310635\n",
      "step =  7200 error value =  0.23578561190012173\n",
      "step =  7600 error value =  0.2241700180835976\n",
      "step =  8000 error value =  0.21361698426066225\n"
     ]
    }
   ],
   "source": [
    "xdata = np.array([ [0, 0], [0, 1], [1, 0], [1, 1] ])\n",
    "tdata = np.array([1, 1, 1, 0])\n",
    "\n",
    "NAND_obj = LogicGate(\"NAND_GATE\", xdata, tdata)\n",
    "\n",
    "NAND_obj.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5299da6a-7d75-4144-9124-dbf98c0c3a6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAND_GATE \n",
      "\n",
      "[0 0]  =  1 \n",
      "\n",
      "[0 1]  =  1 \n",
      "\n",
      "[1 0]  =  1 \n",
      "\n",
      "[1 1]  =  0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(NAND_obj.name, \"\\n\")\n",
    "\n",
    "test_data = np.array([ [0, 0], [0, 1], [1, 0], [1, 1] ])\n",
    "\n",
    "for input_data in test_data:\n",
    "    (sigmoid_val, logical_val) = NAND_obj.predict(input_data)\n",
    "    print(input_data, \" = \", logical_val, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac34b8a-e5b1-403e-ba00-7d2c6033cd7f",
   "metadata": {},
   "source": [
    "#### 1-4. XOR GATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "920e9e05-4e12-4be4-b6fd-5912ab1daf29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial error value =  3.3541575230489147\n",
      "step =  0 error value =  3.341034099716905\n",
      "step =  400 error value =  2.7932625946207748\n",
      "step =  800 error value =  2.7784885702151296\n",
      "step =  1200 error value =  2.7742634835581876\n",
      "step =  1600 error value =  2.7730630396143123\n",
      "step =  2000 error value =  2.772722595041256\n",
      "step =  2400 error value =  2.7726260920580947\n",
      "step =  2800 error value =  2.7725987403815178\n",
      "step =  3200 error value =  2.7725909883283215\n",
      "step =  3600 error value =  2.7725887912349165\n",
      "step =  4000 error value =  2.7725881685319527\n",
      "step =  4400 error value =  2.7725879920444463\n",
      "step =  4800 error value =  2.7725879420240216\n",
      "step =  5200 error value =  2.77258792784713\n",
      "step =  5600 error value =  2.7725879238290854\n",
      "step =  6000 error value =  2.772587922690282\n",
      "step =  6400 error value =  2.7725879223675207\n",
      "step =  6800 error value =  2.7725879222760432\n",
      "step =  7200 error value =  2.7725879222501164\n",
      "step =  7600 error value =  2.772587922242768\n",
      "step =  8000 error value =  2.7725879222406853\n"
     ]
    }
   ],
   "source": [
    "xdata = np.array([ [0, 0], [0, 1], [1, 0], [1, 1] ])\n",
    "tdata = np.array([0, 1, 1, 0])\n",
    "\n",
    "XOR_obj = LogicGate(\"XOR_GATE\", xdata, tdata)\n",
    "\n",
    "XOR_obj.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "354b655c-7ace-4153-9656-0f3eb17c1fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XOR_GATE \n",
      "\n",
      "[0 0]  =  0 \n",
      "\n",
      "[0 1]  =  0 \n",
      "\n",
      "[1 0]  =  0 \n",
      "\n",
      "[1 1]  =  1 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(XOR_obj.name, \"\\n\")\n",
    "\n",
    "test_data = np.array([ [0, 0], [0, 1], [1, 0], [1, 1] ])\n",
    "\n",
    "for input_data in test_data:\n",
    "    (sigmoid_val, logical_val) = XOR_obj.predict(input_data)\n",
    "    print(input_data, \" = \", logical_val, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1505fd25-58ce-483d-90d0-cdc020ef22d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0]  =  0\n",
      "\n",
      "[0 1]  =  1\n",
      "\n",
      "[1 0]  =  1\n",
      "\n",
      "[1 1]  =  0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_data = np.array([ [0,0], [0,1], [1,0], [1, 1] ])\n",
    "\n",
    "s1 = []\n",
    "s2 = []\n",
    "\n",
    "new_input_data = []\n",
    "final_output = []\n",
    "\n",
    "for index in range(len(input_data)):\n",
    "    \n",
    "    s1 = NAND_obj.predict(input_data[index])\n",
    "    s2 = OR_obj.predict(input_data[index])\n",
    "    \n",
    "    new_input_data.append(s1[-1])\n",
    "    new_input_data.append(s2[-1])\n",
    "    \n",
    "    (sigmoid_val, logical_val) = AND_obj.predict(np.array(new_input_data))\n",
    "    \n",
    "    final_output.append(logical_val)\n",
    "    new_input_data = []\n",
    "    \n",
    "for index in range(len(input_data)):\n",
    "    print(input_data[index], \" = \", final_output[index], end = '')\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a521f184-9ecc-421b-9fe5-8d35ad207283",
   "metadata": {},
   "source": [
    "### 2. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "713bec83-e7f6-47f4-876d-e68b8f6163a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1a6e2f49750>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "579d9eb0-ff3a-4764-bb48-2d79871bc2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = [[1,2], [2,3], [3,1], [4,3], [5,3], [6,2]]\n",
    "y_data = [[0], [0], [0], [1], [1], [1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2cb20305-118e-4a63-850d-e00b30c41b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.FloatTensor(x_data)\n",
    "y_train = torch.FloatTensor(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "acc4355a-4ee6-4fe4-96eb-e6aa84c046b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(2, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.sigmoid(self.linear(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e8cf393-1ba7-4957-9b4f-0ac2a0932390",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BinaryClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5127d4a9-7630-4bb5-b1f1-85c66e145ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/100 Cost: 0.539713 Accuracy 83.33%\n",
      "Epoch   10/100 Cost: 0.614853 Accuracy 66.67%\n",
      "Epoch   20/100 Cost: 0.441875 Accuracy 66.67%\n",
      "Epoch   30/100 Cost: 0.373145 Accuracy 83.33%\n",
      "Epoch   40/100 Cost: 0.316358 Accuracy 83.33%\n",
      "Epoch   50/100 Cost: 0.266094 Accuracy 83.33%\n",
      "Epoch   60/100 Cost: 0.220498 Accuracy 100.00%\n",
      "Epoch   70/100 Cost: 0.182095 Accuracy 100.00%\n",
      "Epoch   80/100 Cost: 0.157299 Accuracy 100.00%\n",
      "Epoch   90/100 Cost: 0.144091 Accuracy 100.00%\n",
      "Epoch  100/100 Cost: 0.134272 Accuracy 100.00%\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr = 1)\n",
    "\n",
    "nb_epochs = 100\n",
    "for epoch in range(nb_epochs + 1):\n",
    "    \n",
    "    hypothesis = model(x_train)\n",
    "    \n",
    "    cost = F.binary_cross_entropy(hypothesis, y_train)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % 10 == 0 :\n",
    "        prediction = hypothesis >= torch.FloatTensor([0.5])\n",
    "        correct_prediction = prediction.float() == y_train\n",
    "        accuracy = correct_prediction.sum().item() / len(correct_prediction)\n",
    "        print('Epoch {:4d}/{} Cost: {:.6f} Accuracy {:2.2f}%'.format(\n",
    "            epoch, nb_epochs, cost.item(), accuracy * 100,\n",
    "            ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c211c83-9157-417d-9392-373029150ba7",
   "metadata": {},
   "source": [
    "### 3. Softmax Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "93bbe15f-2751-4ac8-9f6f-56fcdffb1463",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = torch.FloatTensor([1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "780de520-45df-4670-9d71-e0f2c9e6487b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0900, 0.2447, 0.6652])\n"
     ]
    }
   ],
   "source": [
    "hypothesis = F.softmax(z, dim = 0)\n",
    "print(hypothesis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0e285eed-7919-4c2f-b386-1aff327f002c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypothesis.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4c3deeb9-5a32-4403-884f-b62f392ca004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2328, 0.1150, 0.2485, 0.1661, 0.2375],\n",
      "        [0.1990, 0.1746, 0.2133, 0.1903, 0.2228],\n",
      "        [0.1709, 0.2002, 0.1985, 0.2232, 0.2072]], grad_fn=<SoftmaxBackward>)\n"
     ]
    }
   ],
   "source": [
    "z = torch.rand(3, 5, requires_grad = True)\n",
    "hypothesis = F.softmax(z, dim = 1)\n",
    "print(hypothesis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b3ace83e-5cea-4095-837a-c71d73b1a8a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 1, 0])\n"
     ]
    }
   ],
   "source": [
    "y = torch.randint(5, (3, )).long()\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8ce62391-2f24-4134-9a4d-d92853c26a96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_one_hot = torch.zeros_like(hypothesis)\n",
    "y_one_hot.scatter_(1, y.unsqueeze(1), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "721a4d11-617f-4e2c-a41b-4743c2214a71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.6347, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "cost = (y_one_hot * -torch.log(hypothesis)).sum(dim = 1).mean()\n",
    "print(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "641e4345-24ba-448f-917d-c80aefbf3acd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.4574, -2.1628, -1.3922, -1.7949, -1.4377],\n",
       "        [-1.6144, -1.7452, -1.5452, -1.6593, -1.5013],\n",
       "        [-1.7669, -1.6085, -1.6170, -1.4995, -1.5740]], grad_fn=<LogBackward>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.log(F.softmax(z, dim = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fe5059bf-b20e-4f5d-b237-d6a8d49a938d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.4574, -2.1628, -1.3922, -1.7949, -1.4377],\n",
       "        [-1.6144, -1.7452, -1.5452, -1.6593, -1.5013],\n",
       "        [-1.7669, -1.6085, -1.6170, -1.4995, -1.5740]],\n",
       "       grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.log_softmax(z, dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "afec89fc-f1f3-452d-b06d-c30c6f474ca4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.6347, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_one_hot * -torch.log(F.softmax(z, dim = 1))).sum(dim=1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "50f2bbc5-7fa7-42ee-92f2-c63dd06aa8c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.6347, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.nll_loss(F.log_softmax(z, dim=1), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "87346bf0-fbc7-4c0b-acc9-c4a2ec1749a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.6347, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.cross_entropy(z, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0d6b077d-6820-40ac-863b-769325a05e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = [[1, 2, 1, 1],\n",
    "           [2, 1, 3, 2],\n",
    "           [3, 1, 3, 4],\n",
    "           [4, 1, 5, 5],\n",
    "           [1, 7, 5, 5],\n",
    "           [1, 2, 5, 6],\n",
    "           [1, 6, 6, 6],\n",
    "           [1, 7, 7, 7]]\n",
    "y_train = [2, 2, 2, 1, 1, 1, 0, 0]\n",
    "x_train = torch.FloatTensor(x_train)\n",
    "y_train = torch.LongTensor(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "575439a7-8377-48db-a255-a4eae84365cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/1000 Cost: 1.098612\n",
      "Epoch  100/1000 Cost: 0.761050\n",
      "Epoch  200/1000 Cost: 0.689991\n",
      "Epoch  300/1000 Cost: 0.643229\n",
      "Epoch  400/1000 Cost: 0.604117\n",
      "Epoch  500/1000 Cost: 0.568255\n",
      "Epoch  600/1000 Cost: 0.533922\n",
      "Epoch  700/1000 Cost: 0.500291\n",
      "Epoch  800/1000 Cost: 0.466908\n",
      "Epoch  900/1000 Cost: 0.433507\n",
      "Epoch 1000/1000 Cost: 0.399962\n"
     ]
    }
   ],
   "source": [
    "W = torch.zeros((4, 3), requires_grad = True)\n",
    "b = torch.zeros(1, requires_grad = True)\n",
    "\n",
    "optimizer = optim.SGD([W, b], lr = 0.1)\n",
    "\n",
    "nb_epochs = 1000\n",
    "for epoch in range(nb_epochs + 1):\n",
    "    \n",
    "    z = x_train.matmul(W) + b\n",
    "    cost = F.cross_entropy(z, y_train)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % 100 == 0:\n",
    "        print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n",
    "            epoch, nb_epochs, cost.item()\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c304ede1-6167-4cd6-ae18-92750fd14852",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftmaxClassifierModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(4, 3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "80f81d23-a342-420a-9704-3a7edeffdbfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SoftmaxClassifierModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9daa74ce-fd7f-45f2-bc9a-50f01ca5bca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/1000 Cost: 4.661125\n",
      "Epoch  100/1000 Cost: 0.711834\n",
      "Epoch  200/1000 Cost: 0.630354\n",
      "Epoch  300/1000 Cost: 0.573769\n",
      "Epoch  400/1000 Cost: 0.523962\n",
      "Epoch  500/1000 Cost: 0.476843\n",
      "Epoch  600/1000 Cost: 0.430889\n",
      "Epoch  700/1000 Cost: 0.385375\n",
      "Epoch  800/1000 Cost: 0.339988\n",
      "Epoch  900/1000 Cost: 0.295069\n",
      "Epoch 1000/1000 Cost: 0.254579\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr = 0.1)\n",
    "\n",
    "nb_epochs = 1000\n",
    "for epoch in range(nb_epochs + 1):\n",
    "    \n",
    "    prediction = model(x_train)\n",
    "    \n",
    "    cost = F.cross_entropy(prediction, y_train)\n",
    "\n",
    "    # Pytorch는 gradients 값들은 backward 할 때 마다 더해주기 때문에, epoch마다 초기화해줘야 함.\n",
    "    optimizer.zero_grad()\n",
    "    # forward를 정의하면 backword가 자동으로 정의됨\n",
    "    cost.backward()\n",
    "    # parameter update\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % 100 == 0:\n",
    "        print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n",
    "            epoch, nb_epochs, cost.item()\n",
    "        ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3eb70b-bcc8-4809-91a6-fb9be9c57347",
   "metadata": {},
   "source": [
    "### 4. MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "beb6181f-ab9a-4415-8e5a-626978181617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchvision in c:\\users\\user\\anaconda3\\lib\\site-packages (0.10.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\anaconda3\\lib\\site-packages (from torchvision) (1.19.5)\n",
      "Requirement already satisfied: torch==1.9.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from torchvision) (1.9.0)\n",
      "Requirement already satisfied: pillow>=5.3.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from torchvision) (8.2.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch==1.9.0->torchvision) (3.7.4.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2bcb786e-609f-4163-86e7-621914c940da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b8a2ec85-b94d-44b8-87c3-fcf0b0218669",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "mnist_train = dsets.MNIST(root = \"MNIST_data/\", train=True, transform = transforms.ToTensor(),\n",
    "                         download = True)\n",
    "\n",
    "mnist_test = dsets.MNIST(root = \"MNIST_data/\", train=False, transform = transforms.ToTensor(),\n",
    "                         download = True)\n",
    "\n",
    "batch_size = 100\n",
    "\n",
    "data_loader = DataLoader(dataset=mnist_train, batch_size = batch_size,\n",
    "                                    shuffle = True, drop_last = True)\n",
    "\n",
    "# for epoch in range(training_epochs):\n",
    "#     for X, Y in data_loader:\n",
    "#         X = X.view(-1, 28 * 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "35088067-2fb7-45ad-934c-d6a62752e2b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0001 cost = 14.082634926\n",
      "Epoch:  0002 cost = 28.165287018\n",
      "Epoch:  0003 cost = 42.247932434\n",
      "Epoch:  0004 cost = 56.330577850\n",
      "Epoch:  0005 cost = 70.413230896\n",
      "Epoch:  0006 cost = 84.495887756\n",
      "Epoch:  0007 cost = 98.578559875\n",
      "Epoch:  0008 cost = 112.661125183\n",
      "Epoch:  0009 cost = 126.743667603\n",
      "Epoch:  0010 cost = 140.826324463\n",
      "Epoch:  0011 cost = 154.908828735\n",
      "Epoch:  0012 cost = 168.991271973\n",
      "Epoch:  0013 cost = 183.073928833\n",
      "Epoch:  0014 cost = 197.156524658\n",
      "Epoch:  0015 cost = 211.239074707\n",
      "time = 0:01:10.181799\n"
     ]
    }
   ],
   "source": [
    "linear = torch.nn.Linear(784, 10, bias = True)\n",
    "torch.nn.init.normal_(linear.weight)\n",
    "\n",
    "training_epochs = 15\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(linear.parameters(), lr = 0.1)\n",
    "\n",
    "start_time = datetime.now()\n",
    "avg_cost = 0\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    \n",
    "    total_batch = len(data_loader)\n",
    "    \n",
    "    for X, Y in data_loader:\n",
    "        X = X.view(-1, 28 * 28)\n",
    "        optimizer.zero_grad()\n",
    "        hypothesis = linear(X)\n",
    "        cost = criterion(hypothesis, Y)\n",
    "        cost.backward()\n",
    "        avg_cost += cost / total_batch\n",
    "        \n",
    "    print(\"Epoch: \", \"%04d\" % (epoch+1), \"cost =\", \"{:.9f}\".format(avg_cost))\n",
    "    \n",
    "end_time = datetime.now()\n",
    "print(\"time =\", end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4f4b46d0-3331-4ab3-8aac-f6af68b13ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.0917000025510788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:67: UserWarning: test_data has been renamed data\n",
      "  warnings.warn(\"test_data has been renamed data\")\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:57: UserWarning: test_labels has been renamed targets\n",
      "  warnings.warn(\"test_labels has been renamed targets\")\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    X_test = mnist_test.test_data.view(-1, 28 * 28).float()\n",
    "    Y_test = mnist_test.test_labels\n",
    "    \n",
    "    prediction = linear(X_test)\n",
    "    correct_prediction = torch.argmax(prediction, 1) == Y_test\n",
    "    accuracy = correct_prediction.float().mean()\n",
    "    print(\"Accuracy: \", accuracy.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b228d0f8-a9a7-442f-aa74-8c790b85afdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label:  1\n",
      "Prediction:  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:67: UserWarning: test_data has been renamed data\n",
      "  warnings.warn(\"test_data has been renamed data\")\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:57: UserWarning: test_labels has been renamed targets\n",
      "  warnings.warn(\"test_labels has been renamed targets\")\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "r = random.randint(0, len(mnist_test) - 1)\n",
    "X_single_data = mnist_test.test_data[r:r + 1].view(-1, 28 *\n",
    "28).float()\n",
    "Y_single_data = mnist_test.test_labels[r:r + 1]\n",
    "\n",
    "print(\"Label: \", Y_single_data.item())\n",
    "single_prediction = linear(X_single_data)\n",
    "print(\"Prediction: \", torch.argmax(single_prediction,\n",
    "1).item())\n",
    "\n",
    "plt.imshow(mnist_test.test_data[r:r + 1].view(28, 28),\n",
    "cmap=\"Greys\", interpolation=\"nearest\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7a5801-2fde-417b-9a0e-3ae775cd7914",
   "metadata": {},
   "source": [
    "### 5. Backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4efb00ce-90b9-46f8-9b0b-02bbf5b504d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_data.shape =  (60000, 785) test_data.shape =  (10000, 785)\n"
     ]
    }
   ],
   "source": [
    "training_data = np.loadtxt('data/mnist_train.csv', delimiter = ',', dtype = np.float32)\n",
    "test_data = np.loadtxt('data/mnist_test.csv', delimiter = ',', dtype = np.float32)\n",
    "\n",
    "print(\"training_data.shape = \", training_data.shape, \"test_data.shape = \", test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5ec5bf2a-c882-4cfe-9cb1-6373f361921e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = training_data[0][1:].reshape(28, 28)\n",
    "\n",
    "plt.imshow(img, cmap = 'gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "18fe138a-3d7b-4c6b-be22-e1d1f808e071",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / ( 1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "27204449-6495-4b21-8639-fc1a8fb588df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    \n",
    "    def __init__(self, input_nodes, hidden_nodes, output_nodes, learning_rate):\n",
    "        \n",
    "        self.input_nodes = input_nodes\n",
    "        self.hidden_nodes = hidden_nodes\n",
    "        self.output_nodes = output_nodes\n",
    "        \n",
    "        self.W2 = np.random.randn(self.input_nodes, self.hidden_nodes) / np.sqrt(self.input_nodes/2)\n",
    "        self.b2 = np.random.rand(self.hidden_nodes)\n",
    "        \n",
    "        self.W3 = np.random.randn(self.hidden_nodes, self.output_nodes) / np.sqrt(self.hidden_nodes/2)\n",
    "        self.b3 = np.random.rand(self.output_nodes)\n",
    "        \n",
    "        self.Z3 = np.zeros([1, output_nodes])\n",
    "        self.A3 = np.zeros([1, output_nodes])\n",
    "        \n",
    "        self.Z2 = np.zeros([1, hidden_nodes])\n",
    "        self.A2 = np.zeros([1, hidden_nodes])\n",
    "        \n",
    "        self.Z1 = np.zeros([1, input_nodes])\n",
    "        self.A1 = np.zeros([1, input_nodes])\n",
    "        \n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "    def feed_forward(self):\n",
    "        \n",
    "        delta = 1e-7\n",
    "        \n",
    "        self.Z1 = self.input_data\n",
    "        self.A1 = self.input_data\n",
    "        \n",
    "        self.Z2 = np.dot(self.A1, self.W2) + self.b2\n",
    "        self.A2 = sigmoid(self.Z2)\n",
    "        \n",
    "        self.Z3 = np.dot(self.A2, self.W3) + self.b3\n",
    "        self.A3 = sigmoid(self.Z3)\n",
    "        \n",
    "        return np.sum((self.target_data - self.A3) **2) / len(self.target_data)\n",
    "    \n",
    "    def loss_val(self):\n",
    "        \n",
    "        delta = 1e-7\n",
    "        \n",
    "        self.Z1 = self.input_data\n",
    "        self.A1 = self.input_data\n",
    "        \n",
    "        self.Z2 = np.dot(self.A1, self.W2) + self.b2\n",
    "        self.A2 = sigmoid(self.Z2)\n",
    "        \n",
    "        self.Z3 = np.dot(self.A2, self.W3) + self.b3\n",
    "        self.A3 = sigmoid(self.Z3)\n",
    "        \n",
    "        return np.sum((self.target_data - self.A3) **2) / len(self.target_data)\n",
    "    \n",
    "    def train(self, input_data, target_data):\n",
    "        \n",
    "        self.target_data = target_data\n",
    "        self.input_data = input_data\n",
    "        \n",
    "        loss_val = self.feed_forward()\n",
    "        \n",
    "        loss_3 = (self.A3 - self.target_data) * self.A3 * (1-self.A3)\n",
    "        \n",
    "        self.W3 = self.W3 - self.learning_rate * np.dot(self.A2.T, loss_3)\n",
    "        self.b3 = self.b3 - self.learning_rate * loss_3\n",
    "        \n",
    "        loss_2 = np.dot(loss_3, self.W3.T) * self.A2 * (1-self.A2)\n",
    "        \n",
    "        self.W2 = self.W2 - self.learning_rate * np.dot(self.A1.T, loss_2)\n",
    "        \n",
    "        self.b2 = self.b2 - self.learning_rate * loss_2\n",
    "        \n",
    "    def predict(self, input_data):\n",
    "        \n",
    "        Z2 = np.dot(input_data, self.W2) + self.b2\n",
    "        A2 = sigmoid(Z2)\n",
    "        \n",
    "        Z3 = np.dot(A2, self.W3) + self.b3\n",
    "        A3 = sigmoid(Z3)\n",
    "        \n",
    "        predicted_num = np.argmax(A3)\n",
    "        \n",
    "        return predicted_num\n",
    "    \n",
    "    def accuracy(self, test_data):\n",
    "        \n",
    "        matched_list = []\n",
    "        not_matched_list = []\n",
    "        \n",
    "        for index in range(len(test_data)):\n",
    "            \n",
    "            label = int(test_data[index, 0])\n",
    "            \n",
    "            data = (test_data[index, 1:] / 255.0 * 0.99) + 0.01\n",
    "            \n",
    "            predicted_num = self.predict(np.array(data, ndmin = 2))\n",
    "            \n",
    "            if label == predicted_num:\n",
    "                matched_list.append(index)\n",
    "            else:\n",
    "                not_matched_list.append(index)\n",
    "                \n",
    "        print(\"Current Accuracy = \", 100 * (len(matched_list) / (len(test_data))), \" %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d59ee899-2db8-4efc-a219-cabaa7a3c404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 0 , loss_val = 0.9741581219339397\n",
      "step = 400 , loss_val = 0.2812444375799008\n",
      "step = 800 , loss_val = 0.41214650440764966\n",
      "step = 1200 , loss_val = 0.015287382013827226\n",
      "step = 1600 , loss_val = 0.14188155264902352\n",
      "step = 2000 , loss_val = 0.40121319279523954\n",
      "step = 2400 , loss_val = 0.00592518547179214\n",
      "step = 2800 , loss_val = 0.05423056739973844\n",
      "step = 3200 , loss_val = 0.007043585090767172\n",
      "step = 3600 , loss_val = 0.0029286307626587493\n",
      "step = 4000 , loss_val = 0.011835284670484832\n",
      "step = 4400 , loss_val = 0.002842623054611834\n",
      "step = 4800 , loss_val = 0.010838155685282206\n",
      "step = 5200 , loss_val = 0.0035348504396041022\n",
      "step = 5600 , loss_val = 0.007265244391543916\n",
      "step = 6000 , loss_val = 0.0008185305615606513\n",
      "step = 6400 , loss_val = 0.005533215991679035\n",
      "step = 6800 , loss_val = 0.000980999387133718\n",
      "step = 7200 , loss_val = 0.002132196611703218\n",
      "step = 7600 , loss_val = 0.004246857948752866\n",
      "step = 8000 , loss_val = 0.0008771597409816644\n",
      "step = 8400 , loss_val = 0.0028148634313152946\n",
      "step = 8800 , loss_val = 0.0008362468341731185\n",
      "step = 9200 , loss_val = 0.0006839172784358273\n",
      "step = 9600 , loss_val = 0.0008869590583532765\n",
      "step = 10000 , loss_val = 0.0009222623640121533\n",
      "step = 10400 , loss_val = 0.0027901612806060677\n",
      "step = 10800 , loss_val = 0.9335494450018493\n",
      "step = 11200 , loss_val = 0.0021061364245936187\n",
      "step = 11600 , loss_val = 0.9888912662992353\n",
      "step = 12000 , loss_val = 0.003386088939882965\n",
      "step = 12400 , loss_val = 0.0011537946510801985\n",
      "step = 12800 , loss_val = 0.0008982281569445108\n",
      "step = 13200 , loss_val = 0.011038666343269908\n",
      "step = 13600 , loss_val = 0.0008839209158436612\n",
      "step = 14000 , loss_val = 0.0036175116124999946\n",
      "step = 14400 , loss_val = 0.0012256714238122282\n",
      "step = 14800 , loss_val = 0.0008815064438974843\n",
      "step = 15200 , loss_val = 0.0009518555307217929\n",
      "step = 15600 , loss_val = 0.0008505436075275498\n",
      "step = 16000 , loss_val = 0.0009402918243803488\n",
      "step = 16400 , loss_val = 0.006702285579399142\n",
      "step = 16800 , loss_val = 0.0009895764115061142\n",
      "step = 17200 , loss_val = 0.003349623562067693\n",
      "step = 17600 , loss_val = 0.0066539661469139895\n",
      "step = 18000 , loss_val = 0.00569826996668192\n",
      "step = 18400 , loss_val = 0.0007341665402354892\n",
      "step = 18800 , loss_val = 0.0013317248838266764\n",
      "step = 19200 , loss_val = 0.0008755319327813352\n",
      "step = 19600 , loss_val = 0.0008926884992655489\n",
      "step = 20000 , loss_val = 0.000910226869686499\n",
      "step = 20400 , loss_val = 0.0009140978013999023\n",
      "step = 20800 , loss_val = 0.0008568145606170276\n",
      "step = 21200 , loss_val = 0.0008547831806724061\n",
      "step = 21600 , loss_val = 0.0008371618899582826\n",
      "step = 22000 , loss_val = 0.005107905292624715\n",
      "step = 22400 , loss_val = 0.002121158196060258\n",
      "step = 22800 , loss_val = 0.02959934005257143\n",
      "step = 23200 , loss_val = 0.0008464837717103036\n",
      "step = 23600 , loss_val = 0.0007457724620044543\n",
      "step = 24000 , loss_val = 0.0009462591468776146\n",
      "step = 24400 , loss_val = 0.0008777576725145881\n",
      "step = 24800 , loss_val = 0.0007708435967479449\n",
      "step = 25200 , loss_val = 0.0008848297291321034\n",
      "step = 25600 , loss_val = 0.0007483151018398196\n",
      "step = 26000 , loss_val = 0.0008540208071023115\n",
      "step = 26400 , loss_val = 0.0008176242020995495\n",
      "step = 26800 , loss_val = 0.0009604940102170628\n",
      "step = 27200 , loss_val = 0.00116901924457785\n",
      "step = 27600 , loss_val = 0.00099207032906097\n",
      "step = 28000 , loss_val = 0.0007659206368300823\n",
      "step = 28400 , loss_val = 0.0009420316734568239\n",
      "step = 28800 , loss_val = 0.0009069987947014383\n",
      "step = 29200 , loss_val = 0.0009522815216043086\n",
      "step = 29600 , loss_val = 0.0012036672819279214\n",
      "step = 30000 , loss_val = 0.0009869630940770996\n",
      "step = 30400 , loss_val = 0.0014463096874885982\n",
      "step = 30800 , loss_val = 0.0008786439026818256\n",
      "step = 31200 , loss_val = 0.9845583100077439\n",
      "step = 31600 , loss_val = 0.9804292495234733\n",
      "step = 32000 , loss_val = 0.0009316493436426291\n",
      "step = 32400 , loss_val = 0.0013004732871956714\n",
      "step = 32800 , loss_val = 0.0009361579926712436\n",
      "step = 33200 , loss_val = 0.0035912063863335914\n",
      "step = 33600 , loss_val = 0.0008165230462153385\n",
      "step = 34000 , loss_val = 0.004434838007264415\n",
      "step = 34400 , loss_val = 0.0009717874548282363\n",
      "step = 34800 , loss_val = 0.9793177494693314\n",
      "step = 35200 , loss_val = 0.0009188051476154725\n",
      "step = 35600 , loss_val = 0.0008699619407847845\n",
      "step = 36000 , loss_val = 0.0008195956438758993\n",
      "step = 36400 , loss_val = 0.0009021242015037527\n",
      "step = 36800 , loss_val = 0.001335608619120011\n",
      "step = 37200 , loss_val = 0.0008431032743952146\n",
      "step = 37600 , loss_val = 0.0042716544786904785\n",
      "step = 38000 , loss_val = 0.0011302455657256371\n",
      "step = 38400 , loss_val = 0.0008751969052658854\n",
      "step = 38800 , loss_val = 0.003145027103033537\n",
      "step = 39200 , loss_val = 0.00087938006762108\n",
      "step = 39600 , loss_val = 0.979174317079386\n",
      "step = 40000 , loss_val = 0.0008944597501840339\n",
      "step = 40400 , loss_val = 0.0009748022023687137\n",
      "step = 40800 , loss_val = 0.0008464011585847131\n",
      "step = 41200 , loss_val = 0.005346009984187603\n",
      "step = 41600 , loss_val = 0.0009955132587019903\n",
      "step = 42000 , loss_val = 0.0011128146604812695\n",
      "step = 42400 , loss_val = 0.0009174044200199875\n",
      "step = 42800 , loss_val = 0.7850361421214541\n",
      "step = 43200 , loss_val = 0.0007746306150590273\n",
      "step = 43600 , loss_val = 0.0008854218045482917\n",
      "step = 44000 , loss_val = 0.000972040037014467\n",
      "step = 44400 , loss_val = 0.0009482519966766616\n",
      "step = 44800 , loss_val = 0.0007231363802894532\n",
      "step = 45200 , loss_val = 0.0009968286120906327\n",
      "step = 45600 , loss_val = 0.0008421863275613372\n",
      "step = 46000 , loss_val = 0.0008581476084284986\n",
      "step = 46400 , loss_val = 0.0008886565665974782\n",
      "step = 46800 , loss_val = 0.0012152775356096249\n",
      "step = 47200 , loss_val = 0.002308862561630586\n",
      "step = 47600 , loss_val = 1.9336034184083544\n",
      "step = 48000 , loss_val = 0.0012985425515818906\n",
      "step = 48400 , loss_val = 0.0009838411083687257\n",
      "step = 48800 , loss_val = 0.001214240944203413\n",
      "step = 49200 , loss_val = 0.0009999426340965845\n",
      "step = 49600 , loss_val = 0.0008741454873113951\n",
      "step = 50000 , loss_val = 0.0009100592058807459\n",
      "step = 50400 , loss_val = 0.0008397647901354012\n",
      "step = 50800 , loss_val = 0.0009901717702100114\n",
      "step = 51200 , loss_val = 0.007428796783978285\n",
      "step = 51600 , loss_val = 0.9795660951585896\n",
      "step = 52000 , loss_val = 0.000872036382731028\n",
      "step = 52400 , loss_val = 0.0023855896344392984\n",
      "step = 52800 , loss_val = 0.9824433075248724\n",
      "step = 53200 , loss_val = 0.0010599142402871557\n",
      "step = 53600 , loss_val = 0.0007953604150179361\n",
      "step = 54000 , loss_val = 0.0008970362769154884\n",
      "step = 54400 , loss_val = 0.0028008741444799884\n",
      "step = 54800 , loss_val = 0.0009774198937386608\n",
      "step = 55200 , loss_val = 0.0009760573783382024\n",
      "step = 55600 , loss_val = 0.002036839717962943\n",
      "step = 56000 , loss_val = 0.0009369942686628616\n",
      "step = 56400 , loss_val = 0.0008840944933756201\n",
      "step = 56800 , loss_val = 0.9818357525917127\n",
      "step = 57200 , loss_val = 0.0009620256959110941\n",
      "step = 57600 , loss_val = 0.0009625754378063151\n",
      "step = 58000 , loss_val = 0.003064356971984703\n",
      "step = 58400 , loss_val = 0.0009421675741739339\n",
      "step = 58800 , loss_val = 0.0008160361820153519\n",
      "step = 59200 , loss_val = 0.0008936459170576031\n",
      "step = 59600 , loss_val = 0.0009395190278609266\n",
      "time = 0:00:15.809591\n"
     ]
    }
   ],
   "source": [
    "input_nodes = 784\n",
    "hidden_nodes = 100\n",
    "output_nodes = 10\n",
    "learning_rate = 0.3\n",
    "epochs = 1\n",
    "\n",
    "nn = NeuralNetwork(input_nodes, hidden_nodes, output_nodes, learning_rate)\n",
    "\n",
    "start_time = datetime.now()\n",
    "\n",
    "for i in range(epochs):\n",
    "    \n",
    "    for step in range(len(training_data)):\n",
    "        \n",
    "        target_data = np.zeros(output_nodes) + 0.01\n",
    "        target_data[int(training_data[step, 0])] = 0.99\n",
    "        \n",
    "        input_data = ((training_data[step, 1:] / 255.0) * 0.99) + 0.01\n",
    "        \n",
    "        nn.train(np.array(input_data, ndmin = 2), np.array(target_data, ndmin = 2))\n",
    "        \n",
    "        if step % 400 ==0:\n",
    "            print(\"step =\", step, \", loss_val =\", nn.loss_val())\n",
    "            \n",
    "end_time = datetime.now()\n",
    "print(\"time =\", end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c4ff4b33-1224-43e6-abda-ef6401f75e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Accuracy =  94.01  %\n"
     ]
    }
   ],
   "source": [
    "nn.accuracy(test_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
